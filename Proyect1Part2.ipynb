{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 01 - Parte 02\n",
    "**Caso aplicativo**\n",
    "El estudio “CineVision Studios” está complacido con lo que descubrió en el análisis exploratorio que su equipo le entregó. Sin embargo, le han surgido nuevas interrogantes. En la conformación de su equipo de Data Science, uno de los candidatos, en las entrevistas le ha comentado que existen algoritmos que permiten detectar patrones no evidentes en los datos que le proporcionó y “juntar” variables para que\n",
    "sea más pequeño. Le ha pedido que indague un poco más en los datos y extraiga información interesante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesta de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         10000 non-null  int64  \n",
      " 1   budget                     10000 non-null  int64  \n",
      " 2   genres                     9947 non-null   object \n",
      " 3   homePage                   4193 non-null   object \n",
      " 4   productionCompany          9543 non-null   object \n",
      " 5   productionCompanyCountry   8720 non-null   object \n",
      " 6   productionCountry          9767 non-null   object \n",
      " 7   revenue                    10000 non-null  float64\n",
      " 8   runtime                    10000 non-null  int64  \n",
      " 9   video                      9514 non-null   object \n",
      " 10  director                   9926 non-null   object \n",
      " 11  actors                     9920 non-null   object \n",
      " 12  actorsPopularity           9913 non-null   object \n",
      " 13  actorsCharacter            9953 non-null   object \n",
      " 14  originalTitle              10000 non-null  object \n",
      " 15  title                      10000 non-null  object \n",
      " 16  originalLanguage           10000 non-null  object \n",
      " 17  popularity                 10000 non-null  float64\n",
      " 18  releaseDate                10000 non-null  object \n",
      " 19  voteAvg                    10000 non-null  float64\n",
      " 20  voteCount                  10000 non-null  int64  \n",
      " 21  genresAmount               10000 non-null  int64  \n",
      " 22  productionCoAmount         10000 non-null  int64  \n",
      " 23  productionCountriesAmount  10000 non-null  int64  \n",
      " 24  actorsAmount               10000 non-null  int64  \n",
      " 25  castWomenAmount            10000 non-null  object \n",
      " 26  castMenAmount              10000 non-null  object \n",
      "dtypes: float64(3), int64(8), object(16)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyclustertend\n",
    "\n",
    "file_path = \"./movies.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles: ['id', 'budget', 'genres', 'homePage', 'productionCompany', 'productionCompanyCountry', 'productionCountry', 'revenue', 'runtime', 'video', 'director', 'actors', 'actorsPopularity', 'actorsCharacter', 'originalTitle', 'title', 'originalLanguage', 'popularity', 'releaseDate', 'voteAvg', 'voteCount', 'genresAmount', 'productionCoAmount', 'productionCountriesAmount', 'actorsAmount', 'castWomenAmount', 'castMenAmount', 'productionCompanyCountry_count', 'actors_count', 'actorsPopularity_count', 'actorsCharacter_count']\n"
     ]
    }
   ],
   "source": [
    "columns_with_pipes = [\n",
    "    \"genres\", \"productionCompany\", \"productionCompanyCountry\", \n",
    "    \"productionCountry\", \"actors\", \"actorsPopularity\", \"actorsCharacter\"\n",
    "]\n",
    "\n",
    "for col in columns_with_pipes:\n",
    "    df[col + \"_count\"] = df[col].astype(str).apply(lambda x: len(x.split(\"|\")) if pd.notna(x) else 0)\n",
    "\n",
    "df.rename(columns={\n",
    "    'genres_count': 'genresAmount',\n",
    "    'productionCompany_count': 'productionCoAmount',\n",
    "    'productionCountry_count': 'productionCountriesAmount'\n",
    "}, inplace=True)\n",
    "\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "print(\"Columnas disponibles:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_scaled: (39, 13)\n",
      "Vista previa de los datos globalmente estandarizados:\n",
      "   popularity    budget   revenue   runtime  voteCount   voteAvg  \\\n",
      "0   -0.481159 -0.175515 -0.162621 -0.601988   3.434166  0.557957   \n",
      "1   -0.151433 -0.175515 -0.162621 -0.079491   0.173006 -0.591978   \n",
      "2    0.488561 -0.175515 -0.162621  0.599755   0.410408  0.027217   \n",
      "3   -0.536668 -0.175515 -0.162621 -0.671654   1.872308 -0.238152   \n",
      "4   -0.356378 -0.175515 -0.162621 -0.323323  -0.901553  0.734870   \n",
      "\n",
      "   genresAmount  productionCoAmount  productionCountriesAmount  \\\n",
      "0     -0.535672           -0.495439                  -0.436051   \n",
      "1      3.642567           -0.495439                  -0.436051   \n",
      "2     -0.535672            1.574790                   3.343061   \n",
      "3      1.553448            0.194637                  -0.436051   \n",
      "4     -0.535672           -0.495439                  -0.436051   \n",
      "\n",
      "   actorsPopularity  actorsAmount  castWomenAmount  castMenAmount  \n",
      "0          2.624196      0.426401         1.414214      -0.411314  \n",
      "1         -0.252338      0.426401        -0.707107      -0.411310  \n",
      "2         -0.515795      0.426401        -0.707107      -0.411310  \n",
      "3          0.194909      0.426401        -0.707107      -0.411310  \n",
      "4         -0.633547      0.426401        -0.707107      -0.411314  \n"
     ]
    }
   ],
   "source": [
    "numeric_columns = [\"actorsPopularity\", \"castWomenAmount\", \"castMenAmount\"]\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "features = [\n",
    "    'popularity', 'budget', 'revenue', 'runtime', 'voteCount', 'voteAvg',\n",
    "    'genresAmount', 'productionCoAmount', 'productionCountriesAmount',\n",
    "    'actorsPopularity', 'actorsAmount', 'castWomenAmount', 'castMenAmount'\n",
    "]\n",
    "\n",
    "X = df[features].dropna()\n",
    "\n",
    "scaler_global = StandardScaler()\n",
    "X_scaled = scaler_global.fit_transform(X)\n",
    "\n",
    "print(\"Forma de X_scaled:\", X_scaled.shape)\n",
    "\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "print(\"Vista previa de los datos globalmente estandarizados:\")\n",
    "print(df_scaled.head())\n",
    "\n",
    "df_scaled.to_csv(\"movies_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables consideradas por análisis como relevantes agruparlas para su estudio\n",
    "features_rendimiento = ['popularity', 'voteCount', 'voteAvg']\n",
    "features_financiero  = ['budget', 'revenue']\n",
    "features_produccion  = ['runtime', 'genresAmount', 'productionCoAmount', 'productionCountriesAmount']\n",
    "features_reparto     = ['actorsPopularity', 'actorsAmount', 'castWomenAmount', 'castMenAmount']\n",
    "\n",
    "def preparar_subconjunto(dataframe, features):\n",
    "    data = dataframe[features].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled, scaler, data.index\n",
    "\n",
    "data_rendimiento, scaler_rendimiento, indices_rendimiento = preparar_subconjunto(df, features_rendimiento)\n",
    "data_financiero, scaler_financiero, indices_financiero   = preparar_subconjunto(df, features_financiero)\n",
    "data_produccion, scaler_produccion, indices_produccion   = preparar_subconjunto(df, features_produccion)\n",
    "data_reparto, scaler_reparto, indices_reparto             = preparar_subconjunto(df, features_reparto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análsis de la tendencia de agrupamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadístico de Hopkins y VAT (Grupo de variables y subgrupos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hopkins Global: 0.7994553797619387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def hopkins(X):\n",
    "    X = np.array(X)\n",
    "    n, d = X.shape\n",
    "    m = int(0.1 * n)\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "    rand_X = np.random.uniform(np.min(X, axis=0), np.max(X, axis=0), (m, d))\n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(m):\n",
    "        u_dist, _ = nbrs.kneighbors([rand_X[j]], 2, return_distance=True)\n",
    "        random_index = np.random.randint(0, n)\n",
    "        w_dist, _ = nbrs.kneighbors([X[random_index]], 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        wjd.append(w_dist[0][1])\n",
    "    H = np.sum(ujd) / (np.sum(ujd) + np.sum(wjd))\n",
    "    return H\n",
    "\n",
    "hopkins_global = hopkins(X_scaled)\n",
    "print(\"Hopkins Global:\", hopkins_global)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subgrupos (Variables destacadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hopkins Rendimiento: 0.9940114884240647\n",
      "Hopkins Financiero: 0.9933865277480475\n",
      "Hopkins Produccion: 0.9980262501269836\n",
      "Hopkins Reparto: 0.9779591999690042\n"
     ]
    }
   ],
   "source": [
    "groups = {\n",
    "    'Rendimiento': data_rendimiento,\n",
    "    'Financiero': data_financiero,\n",
    "    'Produccion': data_produccion,\n",
    "    'Reparto': data_reparto\n",
    "}\n",
    "\n",
    "for name, data in groups.items():\n",
    "    print(f\"Hopkins {name}:\", hopkins(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
